{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwNZ0igdyMWT"
   },
   "source": [
    "# Final Project: Activation Functions in Graph Neural Networks\n",
    "\n",
    "This project is a continuation of my Senior Capstone Project: \"Exploring the Role of Activation Functions in Deep Learning\". While that research project only examined activation functions in the context of image classification, this notebook attempts to apply several different activation functions to Graph Neural Networks (GNNs). Specifically, we try to classify molecules (represented as graphs) by their scents/odors. Thus, this notebook represents a pivot from image classification to molecular classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-o_tRh0p0r44"
   },
   "source": [
    "We use the Deep Graph Library (DGL) for our Graph Convolutional Neural Networks (GCNNs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fh1FE0lhE9hh",
    "outputId": "eafead0e-28ec-48ca-bebf-264c9ed4ded8"
   },
   "outputs": [],
   "source": [
    "# pip install dgl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLinQJPb82WE"
   },
   "source": [
    "The Open Graph Benchmark (OGB) package contains helpful data loaders for pre-processing and splitting graph data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y62N92-cFWFw",
    "outputId": "6e3ad9d6-07b5-4bb9-f74a-050ac6b19a72"
   },
   "outputs": [],
   "source": [
    "# pip install ogb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SK7laBg7Flj"
   },
   "source": [
    "RDKit is a cheminformatics library that will allow us to convert the input data (SMILES) into RDKit objects which can then be used as DGL objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bm6zJyZrFfHh",
    "outputId": "eef73e27-acad-48ac-b908-a02176ca9bfd"
   },
   "outputs": [],
   "source": [
    "# pip install rdkit-pypi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5IBPhrIz0dg1",
    "outputId": "d2a56ccd-709d-4a81-fc57-459f60c9af99"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# import pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD,Adam,lr_scheduler\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "# Import graph library\n",
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "# import torch\n",
    "# import torch as th\n",
    "import os\n",
    "from ogb.utils.features import (allowable_features, atom_to_feature_vector,\n",
    " bond_to_feature_vector, atom_feature_vector_to_dict, bond_feature_vector_to_dict) \n",
    "from rdkit import Chem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LhS62hp0mb4"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "Next, we upload our training data. The dataset for this experiment was obtained from the AIcrowd Learning to Smell Challenge, which had essentially the same task of identifying the odors of chemical molecules. Of course, this experiment is slightly different because different activation functions will be tested. The training data is formatted as a CSV file with the following two columns:    \n",
    "\n",
    "\n",
    "1.   SMILES (Simplified Molecular-Input Line-Entry System): A line notation for describing the chemical structure of a molecule with short ASCII strings\n",
    "2.   Sentence: A string of odors separated by commas \n",
    "\n",
    "The Sentence data are the target values. There are 4,316 molecules and over 100 different scents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "yflR4vmRFs6q",
    "outputId": "e39b6086-51c6-417f-b9d9-f8f1e23219f3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>SENTENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C/C=C/C(=O)C1CCC(C=C1C)(C)C</td>\n",
       "      <td>fruity,rose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COC(=O)OC</td>\n",
       "      <td>fresh,ethereal,fruity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cc1cc2c([nH]1)cccc2</td>\n",
       "      <td>resinous,animalic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1CCCCCCCC(=O)CCCCCCC1</td>\n",
       "      <td>powdery,musk,animalic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC(CC(=O)OC1CC2C(C1(C)CC2)(C)C)C</td>\n",
       "      <td>coniferous,camphor,fruity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             SMILES                   SENTENCE\n",
       "0       C/C=C/C(=O)C1CCC(C=C1C)(C)C                fruity,rose\n",
       "1                         COC(=O)OC      fresh,ethereal,fruity\n",
       "2               Cc1cc2c([nH]1)cccc2          resinous,animalic\n",
       "3            C1CCCCCCCC(=O)CCCCCCC1      powdery,musk,animalic\n",
       "4  CC(CC(=O)OC1CC2C(C1(C)CC2)(C)C)C  coniferous,camphor,fruity"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the training data and view the first 5 rows\n",
    "df = pd.read_csv('./train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vK8_xtuY6liP"
   },
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code for the Swish and Mish activation functions (Mish is a modified verison of Swish)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement swish activation function\n",
    "def f_swish(input):\n",
    "    '''\n",
    "    Applies the swish function element-wise:\n",
    "    swish(x) = x * sigmoid(x)\n",
    "    '''\n",
    "    return input * torch.sigmoid(input)\n",
    "\n",
    "# implement class wrapper for swish activation function\n",
    "class swish(nn.Module):\n",
    "    '''\n",
    "    Applies the swish function element-wise:\n",
    "    swish(x) = x * sigmoid(x)\n",
    "\n",
    "    Shape:\n",
    "        - Input: (N, *) where * means, any number of additional\n",
    "          dimensions\n",
    "        - Output: (N, *), same shape as the input\n",
    "\n",
    "    Examples:\n",
    "        >>> m = swish()\n",
    "        >>> input = torch.randn(2)\n",
    "        >>> output = m(input)\n",
    "\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Init method.\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        Forward pass of the function.\n",
    "        '''\n",
    "        return f_swish(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement mish activation function\n",
    "def f_mish(input):\n",
    "    '''\n",
    "    Applies the mish function element-wise:\n",
    "    mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + exp(x)))\n",
    "    '''\n",
    "    return input * torch.tanh(F.softplus(input))\n",
    "\n",
    "# implement class wrapper for mish activation function\n",
    "class mish(nn.Module):\n",
    "    '''\n",
    "    Applies the mish function element-wise:\n",
    "    mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + exp(x)))\n",
    "\n",
    "    Shape:\n",
    "        - Input: (N, *) where * means, any number of additional\n",
    "          dimensions\n",
    "        - Output: (N, *), same shape as the input\n",
    "\n",
    "    Examples:\n",
    "        >>> m = mish()\n",
    "        >>> input = torch.randn(2)\n",
    "        >>> output = m(input)\n",
    "\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Init method.\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        Forward pass of the function.\n",
    "        '''\n",
    "        return f_mish(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code for the custom activation functions, TAct and mTAct. These are both designed to interpolate between ReLU, Swish, and Tanh. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "v-e4TiDa60n-"
   },
   "outputs": [],
   "source": [
    "def f_mtact(input, alpha, beta, inplace = False):\n",
    "    '''\n",
    "    Applies the mtact function element-wise:\n",
    "    mtact(x) = ----\n",
    "    '''\n",
    "    A = 0.5*(alpha**2)\n",
    "    B = 0.5 - A\n",
    "    #B=(1-alpha**2)/2\n",
    "    #C = (1+beta**2)/2\n",
    "    C = 0.5*(1+beta**2)\n",
    "\n",
    "    return (A*input + B)*(torch.tanh(C*input)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_ptp6DzX64eE"
   },
   "outputs": [],
   "source": [
    "def f_tact(input, alpha, beta, inplace = False):\n",
    "    '''\n",
    "    Applies the tact function element-wise:\n",
    "    tact(x) = ----\n",
    "    '''\n",
    "    A = 0.5*alpha\n",
    "    B = 0.5 - A\n",
    "    #B=(1-alpha)/2\n",
    "    C = 0.5*(1+beta)\n",
    "\n",
    "    return (A*input + B)*(torch.tanh(C*input)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "YQ7f50u664TK"
   },
   "outputs": [],
   "source": [
    "# implement class wrapper for mtact activation function\n",
    "class mTACT(nn.Module):\n",
    "    '''\n",
    "    Applies the mTACT function element-wise:\n",
    "    mtact(x) = ----\n",
    "\n",
    "    Shape:\n",
    "        - Input: (N, *) where * means, any number of additional\n",
    "          dimensions\n",
    "        - Output: (N, *), same shape as the input\n",
    "\n",
    "    Examples:\n",
    "        >>> m = mtact()\n",
    "        >>> input = torch.randn(2)\n",
    "        >>> output = m(input)\n",
    "\n",
    "    '''\n",
    "    def __init__(self, alpha = np.random.uniform(0,0.5), beta = np.random.uniform(0,0.5),  inplace = False):\n",
    "        \"\"\"\n",
    "        An implementation of our M Tanh Activation Function,\n",
    "        mTACT.\n",
    "        :param alpha a tuneable parameter\n",
    "        :param beta a tuneable parameter\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.alpha = Parameter(torch.tensor(self.alpha,requires_grad=True))\n",
    "\n",
    "        self.beta = beta\n",
    "        self.beta = Parameter(torch.tensor(self.beta,requires_grad=True))\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        Forward pass of the function.\n",
    "        '''\n",
    "        return f_mtact(input, alpha = self.alpha, beta = self.beta, inplace = self.inplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "vp6JtVHy6383"
   },
   "outputs": [],
   "source": [
    "# implement class wrapper for tact activation function\n",
    "class TACT(nn.Module):\n",
    "    '''\n",
    "    Applies the TACT function element-wise:\n",
    "    tact(x) = ----\n",
    "\n",
    "    Shape:\n",
    "        - Input: (N, *) where * means, any number of additional\n",
    "          dimensions\n",
    "        - Output: (N, *), same shape as the input\n",
    "\n",
    "    Examples:\n",
    "        >>> t = tact()\n",
    "        >>> input = torch.randn(2)\n",
    "        >>> output = t(input)\n",
    "\n",
    "    '''\n",
    "    def __init__(self, alpha = np.random.uniform(0,0.5), beta = np.random.uniform(0,0.5),  inplace = False):\n",
    "        \"\"\"\n",
    "        An implementation of our M Tanh Activation Function,\n",
    "        mTACT.\n",
    "        :param alpha a tuneable parameter\n",
    "        :param beta a tuneable parameter\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.alpha = Parameter(torch.tensor(self.alpha,requires_grad=True))\n",
    "\n",
    "        self.beta = beta\n",
    "        self.beta = Parameter(torch.tensor(self.beta,requires_grad=True))\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        Forward pass of the function.\n",
    "        '''\n",
    "        return f_tact(input, alpha = self.alpha, beta = self.beta, inplace = self.inplace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nz_cX6zJBs_B"
   },
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lE4U3KAa_wkA"
   },
   "source": [
    "The `smiles_to_graph` function takes in a SMILES string as input, converts it into an RDKit molecule object, and then returns the input as a DGL graph object. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hljA-pwWFn5V"
   },
   "outputs": [],
   "source": [
    "def smiles_to_graph(smiles_string):\n",
    "    \"\"\"\n",
    "    Converts SMILES string to graph Data object\n",
    "    INPUT: SMILES string (str)\n",
    "    OUTPUT: graph object\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert input into an RDKit molecule object\n",
    "    mol = Chem.MolFromSmiles(smiles_string)\n",
    "\n",
    "    \n",
    "    # Create an adjacency matrix\n",
    "    adjacency_matrix = np.asmatrix(Chem.GetAdjacencyMatrix(mol))\n",
    "    # num_nodes = len(adjacency_matrix)\n",
    "    # Keep only connected nodes \n",
    "    nz_adj_matrix = np.nonzero(adjacency_matrix)\n",
    "    # edge_list = [ ]\n",
    "    src = []\n",
    "    dst = []\n",
    "\n",
    "    for i in range(nz_adj_matrix[0].shape[0]):\n",
    "      src.append(nz_adj_matrix[0][i])\n",
    "      dst.append(nz_adj_matrix[1][i])\n",
    "\n",
    "    graph = dgl.graph((src, dst))\n",
    "    bidirected_graph = dgl.to_bidirected(graph)\n",
    "\n",
    "    return bidirected_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hx99InNJOfdU"
   },
   "source": [
    "Here are two examples demonstrating the DGL graph representation of a given SMILES string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ofWpCJqAKAlY",
    "outputId": "fc007e4c-4913-4173-eacb-5f008c74a797"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=6, num_edges=10,\n",
      "      ndata_schemes={}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "print(smiles_to_graph(\"COC(=O)OC\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7z2DktcJKPtK",
    "outputId": "6473ed3a-13d6-406e-dabd-8ded6208a372"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=17, num_edges=36,\n",
      "      ndata_schemes={}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "print(smiles_to_graph(\"CC(CC(=O)OC1CC2C(C1(C)CC2)(C)C)C\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qI2DaZBzIoAf"
   },
   "source": [
    "The `smiles_to_feat_vec` function takes in a SMILES string as input and then outputs an array of feature vectors. Each atom has a feature vector generated by the `atom_to_feature_vector` method from the OGB library. Each component of the feature vector represents some physical or chemical property of the atom, such as the atomic number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "TJMZSQByIOoM"
   },
   "outputs": [],
   "source": [
    "def smiles_to_feat_vec(smiles_string):\n",
    "    \"\"\"\n",
    "    Returns atom features for a molecule given a SMILES string\n",
    "    INPUT: SMILES string (str)\n",
    "    OUTPUT: graph object\n",
    "    \"\"\"\n",
    "    # Convert input into an RDKit molecule object\n",
    "    molecule = Chem.MolFromSmiles(smiles_string)\n",
    "    # Collect each atom's feature vector in a list\n",
    "    atom_features_list = []\n",
    "    for atom in molecule.GetAtoms():\n",
    "        atom_features_list.append(atom_to_feature_vector(atom))\n",
    "    # Convert the list into a numpy array\n",
    "    atoms_feature_vectors = np.array(atom_features_list, dtype = np.int64)\n",
    "    return atoms_feature_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umJehbcGOkmE"
   },
   "source": [
    "Here are two examples demonstrating the feature vectorizations for a given SMILES string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XI8um2ecKZnH",
    "outputId": "6c9381ea-4a10-484b-fba0-eb76849d1558"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 0 4 5 3 0 2 0 0]\n",
      " [7 0 2 5 0 0 1 0 0]\n",
      " [5 0 3 5 0 0 1 0 0]\n",
      " [7 0 1 5 0 0 1 0 0]\n",
      " [7 0 2 5 0 0 1 0 0]\n",
      " [5 0 4 5 3 0 2 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(smiles_to_feat_vec(\"COC(=O)OC\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lshYSH1BKerW",
    "outputId": "bc8bcea0-754f-48a8-97a3-c5e74cec72a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 0 4 5 3 0 2 0 0]\n",
      " [5 0 4 5 1 0 2 0 0]\n",
      " [5 0 4 5 2 0 2 0 0]\n",
      " [5 0 3 5 0 0 1 0 0]\n",
      " [7 0 1 5 0 0 1 0 0]\n",
      " [7 0 2 5 0 0 1 0 0]\n",
      " [5 0 4 5 1 0 2 0 1]\n",
      " [5 0 4 5 2 0 2 0 1]\n",
      " [5 0 4 5 1 0 2 0 1]\n",
      " [5 0 4 5 0 0 2 0 1]\n",
      " [5 0 4 5 0 0 2 0 1]\n",
      " [5 0 4 5 3 0 2 0 0]\n",
      " [5 0 4 5 2 0 2 0 1]\n",
      " [5 0 4 5 2 0 2 0 1]\n",
      " [5 0 4 5 3 0 2 0 0]\n",
      " [5 0 4 5 3 0 2 0 0]\n",
      " [5 0 4 5 3 0 2 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(smiles_to_feat_vec(\"CC(CC(=O)OC1CC2C(C1(C)CC2)(C)C)C\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWF4alWaLce7"
   },
   "source": [
    "For this experiment, we can first simplify our task by changing it from multiple classification to binary classification. Instead of attempting to identify all scents for a given molecule, we can simply try to determine whether a given molecule has a fruity scent or not. Here, we replace the Sentences with binary digits: \"1\" indicates the presence of a fruity scent, while \"0\" indicates the absence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "eMSih8gvHJZk"
   },
   "outputs": [],
   "source": [
    "# Convert Sentences to a list of strings\n",
    "sentences_list = df['SENTENCE'].to_list()\n",
    "labels = []\n",
    "\n",
    "# Iterate through list of sentences\n",
    "for sentence in sentences_list:\n",
    "  # Split each sentence into a list\n",
    "  sentence = sentence.split(\",\")\n",
    "  # Check for whether \"fruity\" exists in a sentence and add appropriate label\n",
    "  if 'fruity' in sentence:\n",
    "    labels.append(1)\n",
    "  else:\n",
    "    labels.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a list of SMILES objects from our dataframe. We iterate through the list and convert each SMILES object to a graph object. If the graph object can then be properly converted to an OGB feature vector, then it remains in our dataset. Otherwise, it is stored as an exception that is later removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "yXp_NN3fF2jH"
   },
   "outputs": [],
   "source": [
    "# Make a list of graphs\n",
    "molecules_list = df['SMILES'].to_list()\n",
    "\n",
    "# Keep count of the exceptions\n",
    "exception_count = 0\n",
    "\n",
    "# Make listx of graph objects and exception counts\n",
    "graphs = []\n",
    "exceptions = []\n",
    "\n",
    "# Iterate through SMILES objects and try to save valid objects\n",
    "for mol in molecules_list:\n",
    "  g_mol = smiles_to_graph(mol)\n",
    "\n",
    "  try:\n",
    "    g_mol.ndata['feat'] = torch.tensor(smiles_to_feat_vec(mol)) \n",
    "  except:\n",
    "    exceptions.append(exception_count)\n",
    "   \n",
    "  graphs.append(g_mol)\n",
    "  exception_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yB4VFa3ROub7"
   },
   "source": [
    "Any molecules that somehow could not be represented as DGL graph objects are dropped from this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "INXKrAF1_RTq"
   },
   "outputs": [],
   "source": [
    "index = 0\n",
    "for exception_count in exceptions:\n",
    "  graphs.pop(exception_count - index)\n",
    "  labels.pop(exception_count - index)\n",
    "  index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_oVCyOcPuUk"
   },
   "source": [
    "## Prepare Train and Test Datasets Randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we convert our dataset into a DGL dataset by adding labels to each graph from the labels list created earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "uxRV1SvKj5tj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=14, num_edges=28,\n",
      "      ndata_schemes={'feat': Scheme(shape=(9,), dtype=torch.int64)}\n",
      "      edata_schemes={}) tensor(1)\n"
     ]
    }
   ],
   "source": [
    "class SyntheticDataset(DGLDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='synthetic')\n",
    "\n",
    "    def process(self):\n",
    "        #edges = pd.read_csv('./graph_edges.csv')\n",
    "        #properties = pd.read_csv('./graph_properties.csv')\n",
    "        self.graphs = graphs\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.graphs[i], self.labels[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "dataset = SyntheticDataset()\n",
    "# An example of a data point in the pre-processed dataset\n",
    "graph, label = dataset[0]\n",
    "print(graph, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=6, num_edges=10,\n",
      "      ndata_schemes={'feat': Scheme(shape=(9,), dtype=torch.int64)}\n",
      "      edata_schemes={}) tensor(1)\n"
     ]
    }
   ],
   "source": [
    "# Another example of a data point in the pre-processed dataset\n",
    "graph, label = dataset[1]\n",
    "print(graph, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experiment, we use an 80/20 split for our training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "8S_ob4ncMJ3W"
   },
   "outputs": [],
   "source": [
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "num_examples = len(dataset)\n",
    "num_train = int(num_examples * 0.8)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(torch.arange(num_train))\n",
    "test_sampler = SubsetRandomSampler(torch.arange(num_train, num_examples))\n",
    "\n",
    "train_dataloader = GraphDataLoader(\n",
    "    dataset, sampler=train_sampler, batch_size=5, drop_last=False)\n",
    "test_dataloader = GraphDataLoader(\n",
    "    dataset, sampler=test_sampler, batch_size=5, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xU84-lFBP7do"
   },
   "source": [
    "## Define the GCNN then Train & Evaluate Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ny9suxMfLZLp"
   },
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "class GCNN_RELU(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCNN_RELU, self).__init__()\n",
    "        # ACTIVATION FUNCTIONS HERE IN GRAPHCONV (NONE BY DEFAULT)\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        g.ndata['h'] = h\n",
    "        return dgl.mean_nodes(g, 'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for ReLU (Trial 1): 0.7825581395348837\n"
     ]
    }
   ],
   "source": [
    "# Create the model with given dimensions\n",
    "model = GCNN_RELU(9, 8, 2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "        #print(pred,labels)\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "for batched_graph, labels in test_dataloader:\n",
    "    pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "    num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "    num_tests += len(labels)\n",
    "\n",
    "print('Test accuracy for ReLU (Trial 1):', num_correct / num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for ReLU (Trial 2): 0.7802325581395348\n"
     ]
    }
   ],
   "source": [
    "# Create the model with given dimensions\n",
    "model = GCNN_RELU(9, 8, 2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "        #print(pred,labels)\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "for batched_graph, labels in test_dataloader:\n",
    "    pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "    num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "    num_tests += len(labels)\n",
    "\n",
    "print('Test accuracy for ReLU (Trial 2):', num_correct / num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for ReLU (Trial 3): 0.7802325581395348\n"
     ]
    }
   ],
   "source": [
    "# Create the model with given dimensions\n",
    "model = GCNN_RELU(9, 8, 2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "        #print(pred,labels)\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "for batched_graph, labels in test_dataloader:\n",
    "    pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "    num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "    num_tests += len(labels)\n",
    "\n",
    "print('Test accuracy for ReLU (Trial 3):', num_correct / num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test accuracy for ReLU: 0.7810077519379846\n"
     ]
    }
   ],
   "source": [
    "print(\"Average test accuracy for ReLU:\", (0.7825581395348837 + 0.7802325581395348 + 0.7802325581395348) / 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "class GCNN_SWISH(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCNN_SWISH, self).__init__()\n",
    "        # ACTIVATION FUNCTIONS HERE IN GRAPHCONV (NONE BY DEFAULT)\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        SWISH = swish()\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = SWISH.forward(h)\n",
    "        h = self.conv2(g, h)\n",
    "        g.ndata['h'] = h\n",
    "        return dgl.mean_nodes(g, 'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for Swish (Trial 1): 0.7790697674418605\n"
     ]
    }
   ],
   "source": [
    "# Create the model with given dimensions\n",
    "model = GCNN_SWISH(9, 8, 2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "        #print(pred,labels)\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "for batched_graph, labels in test_dataloader:\n",
    "    pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "    num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "    num_tests += len(labels)\n",
    "\n",
    "print('Test accuracy for Swish (Trial 1):', num_correct / num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for Swish (Trial 2): 0.7825581395348837\n"
     ]
    }
   ],
   "source": [
    "# Create the model with given dimensions\n",
    "model = GCNN_SWISH(9, 8, 2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "        #print(pred,labels)\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "for batched_graph, labels in test_dataloader:\n",
    "    pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "    num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "    num_tests += len(labels)\n",
    "\n",
    "print('Test accuracy for Swish (Trial 2):', num_correct / num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for Swish (Trial 3): 0.786046511627907\n"
     ]
    }
   ],
   "source": [
    "# Create the model with given dimensions\n",
    "model = GCNN_SWISH(9, 8, 2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "        #print(pred,labels)\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "for batched_graph, labels in test_dataloader:\n",
    "    pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "    num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "    num_tests += len(labels)\n",
    "\n",
    "print('Test accuracy for Swish (Trial 3):', num_correct / num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test accuracy for Swish: 0.7825581395348836\n"
     ]
    }
   ],
   "source": [
    "print(\"Average test accuracy for Swish:\", (0.7790697674418605 + 0.7825581395348837 + 0.786046511627907) / 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "class GCNN_MISH(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCNN_MISH, self).__init__()\n",
    "        # ACTIVATION FUNCTIONS HERE IN GRAPHCONV (NONE BY DEFAULT)\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.mish(h)\n",
    "        h = self.conv2(g, h)\n",
    "        g.ndata['h'] = h\n",
    "        return dgl.mean_nodes(g, 'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for Mish (Trial 1): 0.7790697674418605\n"
     ]
    }
   ],
   "source": [
    "# Create the model with given dimensions\n",
    "model = GCNN_MISH(9, 8, 2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "        #print(pred,labels)\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "for batched_graph, labels in test_dataloader:\n",
    "    pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "    num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "    num_tests += len(labels)\n",
    "\n",
    "print('Test accuracy for Mish (Trial 1):', num_correct / num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for Mish (Trial 2): 0.7779069767441861\n"
     ]
    }
   ],
   "source": [
    "# Create the model with given dimensions\n",
    "model = GCNN_MISH(9, 8, 2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "        #print(pred,labels)\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "for batched_graph, labels in test_dataloader:\n",
    "    pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "    num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "    num_tests += len(labels)\n",
    "\n",
    "print('Test accuracy for Mish (Trial 2):', num_correct / num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for Mish (Trial 3): 0.7825581395348837\n"
     ]
    }
   ],
   "source": [
    "# Create the model with given dimensions\n",
    "model = GCNN_MISH(9, 8, 2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "        #print(pred,labels)\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "for batched_graph, labels in test_dataloader:\n",
    "    pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "    num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "    num_tests += len(labels)\n",
    "\n",
    "print('Test accuracy for Mish (Trial 3):', num_correct / num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test accuracy for Mish: 0.7798449612403102\n"
     ]
    }
   ],
   "source": [
    "print(\"Average test accuracy for Mish:\", (0.7790697674418605 + 0.7779069767441861 + 0.7825581395348837) / 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "class GCNN_TACT(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCNN_TACT, self).__init__()\n",
    "        # ACTIVATION FUNCTIONS HERE IN GRAPHCONV (NONE BY DEFAULT)\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        tact = TACT()\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = tact.forward(h)\n",
    "        h = self.conv2(g, h)\n",
    "        g.ndata['h'] = h\n",
    "        return dgl.mean_nodes(g, 'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for TAct (Trial 1): 0.7802325581395348\n"
     ]
    }
   ],
   "source": [
    "# Create the model with given dimensions\n",
    "model = GCNN_TACT(9, 8, 2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "        #print(pred,labels)\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "for batched_graph, labels in test_dataloader:\n",
    "    pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "    num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "    num_tests += len(labels)\n",
    "\n",
    "print('Test accuracy for TAct (Trial 1):', num_correct / num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for TAct (Trial 2): 0.7802325581395348\n"
     ]
    }
   ],
   "source": [
    "# Create the model with given dimensions\n",
    "model = GCNN_TACT(9, 8, 2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "        #print(pred,labels)\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "for batched_graph, labels in test_dataloader:\n",
    "    pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "    num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "    num_tests += len(labels)\n",
    "\n",
    "print('Test accuracy for TAct (Trial 2):', num_correct / num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for TAct (Trial 3): 0.7825581395348837\n"
     ]
    }
   ],
   "source": [
    "# Create the model with given dimensions\n",
    "model = GCNN_TACT(9, 8, 2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "        #print(pred,labels)\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "for batched_graph, labels in test_dataloader:\n",
    "    pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "    num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "    num_tests += len(labels)\n",
    "\n",
    "print('Test accuracy for TAct (Trial 3):', num_correct / num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test accuracy for TAct: 0.7810077519379846\n"
     ]
    }
   ],
   "source": [
    "print(\"Average test accuracy for TAct:\", (0.7802325581395348 + 0.7802325581395348 + 0.7825581395348837) / 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mTAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "class GCNN_MTACT(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCNN_MTACT, self).__init__()\n",
    "        # ACTIVATION FUNCTIONS HERE IN GRAPHCONV (NONE BY DEFAULT)\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        mtact = mTACT()\n",
    "        h = mtact(h)\n",
    "        h = self.conv2(g, h)\n",
    "        g.ndata['h'] = h\n",
    "        return dgl.mean_nodes(g, 'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for mTAct (Trial 1): 0.7825581395348837\n"
     ]
    }
   ],
   "source": [
    "# Create the model with given dimensions\n",
    "model = GCNN_MTACT(9, 8, 2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "        #print(pred,labels)\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "for batched_graph, labels in test_dataloader:\n",
    "    pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "    num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "    num_tests += len(labels)\n",
    "\n",
    "print('Test accuracy for mTAct (Trial 1):', num_correct / num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for mTAct (Trial 2): 0.7790697674418605\n"
     ]
    }
   ],
   "source": [
    "# Create the model with given dimensions\n",
    "model = GCNN_MTACT(9, 8, 2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "        #print(pred,labels)\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "for batched_graph, labels in test_dataloader:\n",
    "    pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "    num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "    num_tests += len(labels)\n",
    "\n",
    "print('Test accuracy for mTAct (Trial 2):', num_correct / num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for mTAct (Trial 3): 0.7825581395348837\n"
     ]
    }
   ],
   "source": [
    "# Create the model with given dimensions\n",
    "model = GCNN_MTACT(9, 8, 2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "        #print(pred,labels)\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "for batched_graph, labels in test_dataloader:\n",
    "    pred = model(batched_graph, batched_graph.ndata['feat'].float())\n",
    "    num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "    num_tests += len(labels)\n",
    "\n",
    "print('Test accuracy for mTAct (Trial 3):', num_correct / num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test accuracy for mTAct: 0.7813953488372093\n"
     ]
    }
   ],
   "source": [
    "print(\"Average test accuracy for mTAct:\", (0.7825581395348837 + 0.7790697674418605 + 0.7825581395348837) / 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the activation functions significantly outperformed the others in accuracy on this particular task. However, there are many other avenues to explore in graph neural network tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuChabWWZ2Ja"
   },
   "source": [
    "Credit: Basis of experiment and code provided by\n",
    " https://towardsdatascience.com/learn-to-smell-molecules-with-graph-convolutional-neural-networks-62fa5a826af5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZdH0UcOhaVS7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ACS 4511 Final Project",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
